{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='train-test-scratch'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "### 1. train test split from scratch\n",
    "\n",
    "Create a function my_train_test_split() that takes ipnput X, y and fraction of train. And ouputs the list or tuple containing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clue 1: Splitting the data sequentially for a given fraction\n",
    "\n",
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0], [9, 10, 1], [11, 12, 0]])\n",
    "print('data:')\n",
    "print(data)\n",
    "\n",
    "# Train part of the data\n",
    "split = int(0.8*data.shape[0])\n",
    "X_train = data[:split, :-1]\n",
    "y_train = data[:split, -1]\n",
    "\n",
    "print('\\nX_train:')\n",
    "print(X_train)\n",
    "print('\\ny_train:')\n",
    "print(y_train)\n",
    "\n",
    "# The test part of the data\n",
    "X_test = data[split:, :-1]\n",
    "y_test = data[split:, -1]\n",
    "\n",
    "print('\\ny_train:')\n",
    "print(X_test)\n",
    "\n",
    "print('\\ny_test:')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clue2: splitting data randomly\n",
    "data = np.array([[1, 2, 0], [3, 4, 1], [5, 6, 1], [7, 8, 0]])\n",
    "num_samples = data.shape[0]\n",
    "ind = np.random.choice(num_samples, num_samples, replace = False)\n",
    "print(ind)\n",
    "print(type(ind))\n",
    "split = int(0.8*num_samples)\n",
    "print(split)\n",
    "ind[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your function definition goes here\n",
    "def my_train_test_split(X,y,test_size,random_state):\n",
    "    if random_state:\n",
    "        random.seed(random_state)\n",
    "    data = list(zip(X,y))\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    split = int((1-test_size)*len(data))\n",
    "\n",
    "    train_data = data[:split]\n",
    "    test_data = data[split:]\n",
    "    \n",
    "    X_train, y_train = zip(*train_data)\n",
    "    X_test, y_test = zip(*test_data)\n",
    "\n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Your function invocation goes here\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "X_train , y_train , X_test , y_test = my_train_test_split(X,y,0.2,random_state=42)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='knn-scratch'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. kNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN class that allows setting the number of neighbours and weight=uniform or distance\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for test_sample in X_test:\n",
    "            distances = [np.linalg.norm(test_sample - train_sample) for train_sample in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            most_common_label = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "            predictions.append(most_common_label)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNN(k=3)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "acc = accuracy_score(predictions,y_test)\n",
    "print(f\"Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gridsearch-scratch'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GridSearch from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clue: Look at itertools.product() functionality in python.\n",
    "# It will allow you to create Cartesian products needed for multiple hyperparam tuning\n",
    "# Use it in a loop to write your custom Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_grid_search(X_train,y_train,X_test,param_grid,k_values):\n",
    "    best_params=None\n",
    "    best_accuracy=-1\n",
    "\n",
    "    for k in k_values:\n",
    "        knn = KNN(k=k)\n",
    "        knn.fit(X_train,y_train)\n",
    "        predictions = knn.predict(X_test)\n",
    "        accuracy = (predictions==y_test).mean()\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "           best_accuracy = accuracy\n",
    "           best_params = {'n_neighbors': k} \n",
    "        \n",
    "    return best_params, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "\n",
    "best_params, best_accuracy = my_grid_search(X_train, y_train, X_test, param_grid, k_values)\n",
    "\n",
    "print(\"Best K value found:\", best_params['n_neighbors'])\n",
    "print(\"Accuracy of the best model:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='integrate'></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Integrate your custom code\n",
    "\n",
    "1. Create a dataframe of iris dataset\n",
    "2. Use your custom train test split function to split into train and test\n",
    "3. Use your custom GridSearch on your customKNN class to identify the best k and best weight for iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    data = list(zip(X, y))\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    split_index = int(len(data) * (1 - test_size))\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "\n",
    "    X_train, y_train = zip(*train_data)\n",
    "    X_test, y_test = zip(*test_data)\n",
    "\n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for test_sample in X_test:\n",
    "            distances = [np.linalg.norm(test_sample - train_sample) for train_sample in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            most_common_label = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "            predictions.append(most_common_label)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def my_grid_search(X_train,y_train,X_test,param_grid,k_values):\n",
    "        best_params=None\n",
    "        best_accuracy=-1\n",
    "\n",
    "        for k in k_values:\n",
    "            knn = KNN(k=k)\n",
    "            knn.fit(X_train,y_train)\n",
    "            predictions = knn.predict(X_test)\n",
    "            accuracy = (predictions==y_test).mean()\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'n_neighbors': k} \n",
    "            \n",
    "        return best_params, best_accuracy\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7, 9]}\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "best_params, best_accuracy = my_grid_search(X_train, y_train, X_test, param_grid, k_values)\n",
    "\n",
    "print(\"Best K value found:\", best_params['n_neighbors'])\n",
    "print(\"Accuracy of the best model:\", best_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
