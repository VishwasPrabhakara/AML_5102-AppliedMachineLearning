{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"aml-assignment1\"></a>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. AML class exercise/mandatory assignment 1\n",
    "\n",
    "In the course of this lab, you used NearestCentroid class from sklearn library and used it to make predictions from scratch\n",
    "Now you have the knowledge to write a similar NearestCentroid from scratch.\n",
    "\n",
    "Your custom NearestCentroid implementation should be able to accept any dataset as input, with any number of labels and do the prediction.\n",
    "But first, code your custom Nearest Centroid implementation specifically for Iris dataset with 3 labels and then generalize for n labels.\n",
    "\n",
    "1. Separate the dataset into n labels by using the boolean mask based indexing\n",
    "2. Calculate the centroid of each class. \n",
    "3. For any incoming test data, check the distance of each test data point from the centroid. Each test data point belongs to that class to whose centroid it is closest\n",
    "4. For the given train test split, verify your code prediction is same as sklearn NearestCentroid prediction \n",
    "5. **<font color=\"red\">Write the code as reusable Python classes along the lines of sklearn classes (but dont aim for it at the outset)</font>**\n",
    "\n",
    "Hint: \n",
    "1. To calculate the distance between any two data points a and b, use the np.linalg.norm(a-b). In this case distance between all test points and all centroids should be calculated.\n",
    "2. You can implement this with the traditional two nested for loops. Or if you can use vectorization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "y = df.pop(\"target\").to_numpy()\n",
    "X = df.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sk = NearestCentroid()\n",
    "model_sk.fit(X_train, y_train)\n",
    "y_pred = model_sk.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sk.centroids_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNearestCentroid:\n",
    "    def fit(self, X, y):\n",
    "        self.labels = np.unique(y)\n",
    "        self.centroids = []\n",
    "        for lbl in self.labels:\n",
    "            mask = y == lbl\n",
    "            X_lbl = X[mask]\n",
    "            centroid = np.mean(X_lbl, axis=0)\n",
    "            self.centroids.append(centroid)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        prediction with traditional nested loop\n",
    "        This function has a sneaky bug that prevents it from working as expected.\n",
    "        Identify & fix the bug & ping me your answers. This is first part of AML assignment 1\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        num_records = X.shape[0]\n",
    "        y_pred_distances = np.empty((num_records, len(self.labels)))\n",
    "        for i in np.arange(0,num_records):\n",
    "            for j, centroid in enumerate(self.centroids):\n",
    "                y_pred_distances[i, j] = np.linalg.norm(X[i] - centroid[j], axis=0)\n",
    "\n",
    "        y_pred =  np.argmin(y_pred_distances, axis=1)\n",
    "        return y_pred\n",
    "    \n",
    "    \"\"\"\n",
    "        TODO: Add vectorized code to do prediction\n",
    "        This is second part of AML assignment 1\n",
    "    \"\"\"\n",
    "    def predict_vectorized(self, X):\n",
    "        centroids = np.array(self.centroids)\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
    "        y_pred = np.argmin(distances, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MyNearestCentroid()\n",
    "mymodel.fit(X_train, y_train)\n",
    "\n",
    "print(mymodel.labels)\n",
    "mymodel.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mymodel.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
