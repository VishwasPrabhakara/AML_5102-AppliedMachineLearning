{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. tanh\n",
    "$$\n",
    "y = tanh(x) = \\frac{sinh(x)}{cosh(x)} = \\frac{e^{2x} -1}{e^{2x} + 1}\n",
    "$$\n",
    "\n",
    "$x \\in (-\\infty, +\\infty)$, $y \\in [-1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_array = np.linspace(-np.pi, np.pi, 12) \n",
    "out_array = np.tanh(in_array) \n",
    "  \n",
    "print(\"in_array : \", in_array) \n",
    "print(\"\\nout_array : \", out_array) \n",
    "  \n",
    "# red for numpy.tanh() \n",
    "plt.plot(in_array, out_array, color = 'red', marker = \"o\") \n",
    "plt.title(\"numpy.tanh()\") \n",
    "plt.xlabel(\"X\") \n",
    "plt.ylabel(\"Y\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sigmoid\n",
    "\n",
    "$$\n",
    "y = \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "$x \\in (-\\infty, +\\infty)$, $y \\in [0,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_array = np.linspace(-5, 5, 25) \n",
    "out_array = sigmoid(in_array) \n",
    "  \n",
    "print(\"in_array : \", in_array) \n",
    "print(\"\\nout_array : \", out_array) \n",
    "  \n",
    "# red for numpy.tanh() \n",
    "plt.plot(in_array, out_array, color = 'red', marker = \"o\") \n",
    "plt.title(\"sigmoid\") \n",
    "plt.xlabel(\"X\") \n",
    "plt.ylabel(\"Y\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Log of odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.linspace(0.00001, 0.999999, 50) \n",
    "odds_ratio = p/(1-p)\n",
    "log_odds = np.log(odds_ratio)\n",
    "\n",
    "print(\"in_array : \", p) \n",
    "print(\"\\nout_array : \", log_odds) \n",
    "  \n",
    "# red for numpy.tanh() \n",
    "plt.plot(p, log_odds, color = 'red', marker = \"o\") \n",
    "plt.title(\"Log Odds\") \n",
    "plt.xlabel(\"Probability\") \n",
    "plt.ylabel(\"Log of odds\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "log \\biggr(\\frac{p}{1-p} \\biggr) = w_1x_1 + w_2x_2 + .... w_nx_n + b = w^Tx + b\n",
    "$$\n",
    "Simplifying and reordering we get\n",
    "$$\n",
    "p = \\frac{1}{1+e^{-(w^Tx+b)}} = \\sigma(w^Tx+b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = titanic[0]\n",
    "df_titanic['survived'] = titanic[1] \n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique values for feature cabin {df_titanic['cabin'].nunique()}\")\n",
    "print(f\"Unique values for feature body {df_titanic['body'].nunique()}\")\n",
    "print(f\"Unique values for feature boat {df_titanic['boat'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.drop(columns=[\"name\", \"ticket\", \"cabin\", \"body\", \"home.dest\", \"boat\"], inplace=True)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.drop(np.where(df_titanic[\"embarked\"].isna())[0], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"fare\"].isna())[0], inplace=True)\n",
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_titanic.iloc[:,:-1:]\n",
    "y = df_titanic.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl_encoder = LabelEncoder()\n",
    "sex_train_encoded = lbl_encoder.fit_transform(X_train[\"sex\"])\n",
    "sex_test_encoded = lbl_encoder.transform(X_test[\"sex\"])\n",
    "\n",
    "lbl_encoder2 = LabelEncoder()\n",
    "embark_train_encoded = lbl_encoder.fit_transform(X_train[\"embarked\"])\n",
    "embark_test_encoded = lbl_encoder.transform(X_test[\"embarked\"])\n",
    "\n",
    "tgt_encoder = LabelEncoder()\n",
    "y_train_encoded = tgt_encoder.fit_transform(y_train)\n",
    "y_test_encoded = tgt_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.hstack( \n",
    "    (X_train.iloc[:,0:1].to_numpy(), sex_train_encoded.reshape(-1,1), \n",
    "     X_train.iloc[:,2:6].to_numpy(), embark_train_encoded.reshape(-1,1)))\n",
    "X_test_new = np.hstack(\n",
    "    (X_test.iloc[:,0:1].to_numpy(), sex_test_encoded.reshape(-1,1), \n",
    "     X_test.iloc[:,2:6].to_numpy(), embark_test_encoded.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=7, weights='uniform', metric='nan_euclidean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_new)\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_imputed = imputer.transform(X_test_new)\n",
    "X_test_imputed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_imputed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = clf.score(X_train_imputed, y_train)\n",
    "print(f'Train accuracy: {train_accuracy * 100:.3f}%')\n",
    "\n",
    "test_accuracy = clf.score(X_test_imputed, y_test)\n",
    "print(f'Test accuracy: {test_accuracy * 100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solvers**\n",
    "\n",
    "https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-definitions/52388406#52388406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "params = dict(solver=solver_list)\n",
    "log_reg = LogisticRegression(C=1, n_jobs=-1, random_state=34)\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "clf.fit(X_train_imputed, y_train)\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "\n",
    "for score, solver in zip(scores, solver_list):\n",
    "    print(f\"  {solver} {score:.3f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multiclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = load_wine()\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "df = pd.DataFrame(X, columns=rd.feature_names)\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:,-1], random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = np.zeros_like(X_train.corr(), dtype=bool)\n",
    "mask[np.triu_indices_from(mask)]= True\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Wine Feature Correlation Matrix\", fontsize=40)\n",
    "x = sns.heatmap(\n",
    "    X_train.corr(), \n",
    "    cmap='coolwarm',\n",
    "    annot=True,\n",
    "    mask=mask,\n",
    "    linewidths = .5,\n",
    "    vmin = -1, \n",
    "    vmax = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=34, solver='lbfgs', multi_class=\"auto\", n_jobs=-1, C=1)\n",
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = logistic_regression_model.score(X_test, y_test)\n",
    "accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "parameters = dict(solver=solver_list)\n",
    "lr = LogisticRegression(random_state=34, multi_class=\"auto\", n_jobs=-1, C=1)\n",
    "clf = GridSearchCV(lr, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.cv_results_['mean_test_score']\n",
    "for score, solver, in zip(scores, solver_list):\n",
    "    print(f\"{solver}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=solver_list, y=scores). set_title(\"Wine Accuracy with Unscaled Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "parameters = dict(solver=solver_list)\n",
    "lr = LogisticRegression(random_state=34, multi_class=\"auto\", n_jobs=-1, C=1)\n",
    "clf = GridSearchCV(lr, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_['mean_test_score']\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "for score, solver, in zip(scores, solver_list):\n",
    "    print(f\"{solver}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax =sns.barplot(x=solver_list, y=scores).set_title(\"Wine Accuracy with Scaled Features\", fontsize=\"20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One versus Rest and One Versus One**\n",
    "\n",
    "https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/\n",
    "\n",
    "When to use which\n",
    "1. When data is imbalanced, prefer OVO\n",
    "\n",
    "SVM too has similar OVO and OVR support in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
