{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Non Vectorized implementation with single variable\n",
    "\n",
    "$$\n",
    "\\hat{y} = wx + b \\\\\n",
    "error^{(i)} = \\hat{y}^{(i)} - y^{(i)} \\\\\n",
    "\\mathcal{J}(w, b) = \\frac{1}{n} \\sum_{i=1}^n{\\hat{y}^{(i)} - y^{(i)})}^2 \\\\\n",
    "\\mathcal{J}(w, b) = \\frac{1}{n} \\sum_{i=1}^n{(\\hat{y}^{(i)} - y^{(i)})}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate the cost\n",
    "def compute_cost(x, y, w, b):\n",
    "    m = x.shape[0] \n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial{\\mathcal{J}}}{\\partial{b}} = \\frac{\\partial{\\mathcal{J}}}{\\partial{\\hat{y}^{(i)}}} \\frac{\\partial{\\hat{y}^{(i)}}}{\\partial{b}} \\hspace{4 mm} = \\frac{1}{m} \\sum_{i=1}^m{2(b + w x^{(i)} - y^{(i)})} \\\\\n",
    "\n",
    "\\frac{\\partial{\\mathcal{J}}}{\\partial{w}} = \\frac{\\partial{\\mathcal{J}}}{\\partial{\\hat{y}^{(i)}}} \\frac{\\partial{\\hat{y}^{(i)}}}{\\partial{w}} = \\frac{1}{m} \\sum_{i=1}^m{2x^{(i)}(b + w x^{(i)} - y^{(i)})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "      w,b (scalar)    : model parameters  \n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \n",
    "     \"\"\"\n",
    "    \n",
    "    # Number of training examples\n",
    "    m = x.shape[0]    \n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):  \n",
    "        f_wb = w * x[i] + b \n",
    "        dj_dw_i = (f_wb - y[i]) * x[i] \n",
    "        dj_db_i = f_wb - y[i] \n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i \n",
    "    dj_dw = dj_dw / m \n",
    "    dj_db = dj_db / m \n",
    "        \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b = b - \\eta \\frac{\\partial{\\mathcal{J}}}{\\partial{b}} \\\\\n",
    "\n",
    "w = w - \\eta \\frac{\\partial{\\mathcal{J}}}{\\partial{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function): \n",
    "    \"\"\"\n",
    "    Performs gradient descent to fit w,b. Updates w,b by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      x (ndarray (m,))  : Data, m examples \n",
    "      y (ndarray (m,))  : target values\n",
    "      w_in,b_in (scalar): initial values of model parameters  \n",
    "      alpha (float):     Learning rate\n",
    "      num_iters (int):   number of iterations to run gradient descent\n",
    "      cost_function:     function to call to produce cost\n",
    "      gradient_function: function to call to produce gradient\n",
    "      \n",
    "    Returns:\n",
    "      w (scalar): Updated value of parameter after running gradient descent\n",
    "      b (scalar): Updated value of parameter after running gradient descent\n",
    "      J_history (List): History of cost values\n",
    "      p_history (list): History of parameters [w,b] \n",
    "      \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w_in) # avoid modifying global w_in\n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    b = b_in\n",
    "    w = w_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # Calculate the gradient and update the parameters using gradient_function\n",
    "        dj_dw, dj_db = gradient_function(x, y, w , b)     \n",
    "\n",
    "        # Update Parameters using equation (3) above\n",
    "        b = b - alpha * dj_db                            \n",
    "        w = w - alpha * dj_dw                            \n",
    "\n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(x, y, w , b))\n",
    "            p_history.append([w,b])\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0:\n",
    "            # print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e} \",\n",
    "            #       f\"dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  \",\n",
    "            #       f\"w: {w: 0.3e}, b:{b: 0.5e}\")\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]} \",\n",
    "                  f\"dj_dw: {dj_dw}, dj_db: {dj_db}  \",\n",
    "                  f\"w: {w}, b:{b}\")\n",
    " \n",
    "    return w, b, J_history, p_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_b = 1\n",
    "true_w = 2\n",
    "N = 100\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create an array of the given shape and populate it with random samples \n",
    "# from a uniform distribution over [0, 1)\n",
    "X = np.random.rand(N, 1)\n",
    "epsilon = (.1 * np.random.randn(N, 1))\n",
    "\n",
    "y = true_b + true_w * X + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({ \"x\": X.tolist(), \"y\": y.tolist()})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "# some gradient descent settings\n",
    "iterations = 10000\n",
    "tmp_alpha = 1.0e-2\n",
    "# run gradient descent\n",
    "w_final, b_final, J_hist, p_hist = gradient_descent(X_train ,y_train, w_init, b_init, tmp_alpha, \n",
    "                                                    iterations, compute_cost, compute_gradient)\n",
    "\n",
    "#Compare the w and b obtained with gradient descent with actual values\n",
    "print(f\"(w,b) found by gradient descent: ({w_final},{b_final})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load dataset for multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Diabetes dataset\n",
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Convert the iris dataset to a pandas dataframe\n",
    "df = pd.DataFrame(data.data, columns=[\"age\",\"sex\",\"bmi\",\"bp\", \"tc\", \"ldl\", \"hdl\",\"tch\", \"ltg\", \"glu\"])\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "df['target'] = data.target\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#describing dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "1. All features except target have the same standard deviation\n",
    "2. Apart from target column and a couple of exceptions, the rest of the features have the same order of magnitude (mean, min, max and percentiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying mask\n",
    "mask = np.triu(np.ones_like(df.corr()))\n",
    "\n",
    "#correlation matrix\n",
    "dataplot = sns.heatmap(df.corr(), annot=True, fmt='.2f', mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**:\n",
    "1. No high correlation between features. i.e. no multicollinearity to worry about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['bmi', 'ltg', 'tch', 'target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df, x='bmi', y='target',line_kws={\"color\": \"red\"})\n",
    "plt.title(\"BMI v/s Target\")\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df, x='ltg', y='target',line_kws={\"color\": \"red\"})\n",
    "plt.title(\"LTG v/s Target\")\n",
    "plt.xlabel(\"LTG\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**:\n",
    "\n",
    "1. Relationship between ltg/bmi with target is mostly linear. There is slight heteroskedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multiple Linear Regression with Vectorized implementation\n",
    "\n",
    "$$\n",
    "\\mathcal{J}(w) = \\frac{1}{m} (Xw - y)^T(Xw - y) \\\\\n",
    "\\nabla_w J = \\frac{2}{m} X^T (Xw - y) \\\\\n",
    "\\textbf{w} = \\textbf{w} - \\eta \\nabla_w J \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_compute_cost(X, y, w):\n",
    "    m = len(y)\n",
    "    predictions = np.dot(X, w)\n",
    "    error = predictions - y\n",
    "    cost = (1 / (2 * m)) * np.sum(error**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_compute_gradient(X, y, w):\n",
    "    m = len(y)\n",
    "    predictions = np.dot(X, w)\n",
    "    error = predictions - y\n",
    "    gradient = (1 / m) * np.dot(X.T, error)\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, learning_rate, num_epochs):\n",
    "    m = len(y)\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        cost = vectorized_compute_cost(X, y, w)\n",
    "\n",
    "        gradient = vectorized_compute_gradient(X, y, w)\n",
    "        \n",
    "        w -= learning_rate * gradient\n",
    "\n",
    "        loss_history.append(cost)\n",
    "\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data matrix X should be augmented with 1s in the first column that correspond to bias (intercept) weight w_0\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & x^{(1)}_1 & .. & x^{(1)}_n \\\\\n",
    "1 & x^{(2)}_1 & .. & x^{(2)}_n\\\\\n",
    "1 & ..  & .. & ..\\\\\n",
    "1 & x^{(m)}_1 & .. & x^{(m)}_n\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X.shape\n",
    "#notice augmenting the data matrix with first column of 1s \n",
    "X = np.hstack((np.ones(X.shape[0]).reshape(-1,1), X)) \n",
    "X[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "num_epochs = 50000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Initialize weight params\n",
    "w = np.zeros(X.shape[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "w, loss_history = gradient_descent(X_train, y_train, w, learning_rate, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curve\n",
    "plt.plot(range(num_epochs), loss_history)\n",
    "plt.xlabel(\"Epoch/Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epoch/Iteration versus Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make predictions with custom vectorized linear regression\n",
    "\n",
    "R-squared is very low. This is expected because Linear Regression is not a good model for diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_custom = np.dot(X_train, w)\n",
    "y_test_pred_custom = np.dot(X_test, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Linear Regression Metrics\n",
    "print(f'Mean absolute error is:{mean_absolute_error(y_test, y_test_pred_custom): .2f}')\n",
    "print(f'Root mean squared error is:{np.sqrt(mean_squared_error(y_test, y_test_pred_custom)): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, y_train_pred_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_test_pred_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots\n",
    "\n",
    "The following plots are made\n",
    "1. Actual V/s Predicted - Plotting actual data against the fitted line - shows if there is clear tendency for points to be distributed around the line - in our case no.\n",
    "2. KDE of actual and predicted - This shows whether probability density of predicted values ​​does approximates real values (or not) - In our case it does not\n",
    "3. Residual versus predicted - This plot tells if the residuals are randomly distributed uniformly around the fitted line - in our case it is indeed the case, but the error is too high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_actual_vs_predicted(y, y_pred, title, x_label, y_label):\n",
    "    #figure size\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    #scatterplot of y y_pred\n",
    "    plt.scatter(y, y_pred)\n",
    "    plt.plot(y_test, y_test, color='r')\n",
    "\n",
    "    #labeling\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    #showig plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_actual_vs_predicted(y_test, y_test_pred_custom, \n",
    "                         'Actual versus predicted values for test data',\n",
    "                         'Actual Values', 'Predicted values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde_actual_vs_predicted(y, y_pred, title, actual_label, predicted_label):\n",
    "    ''' \n",
    "    The plot(kde) function plots the KDE. Inputs are just real and predicted y values, in this order:\n",
    "    y, y_pred\n",
    "    '''\n",
    "    #figsize\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    #Kernel Density Estimation plot\n",
    "    ax = sns.kdeplot(y, color='r', label=actual_label) #actual values\n",
    "    sns.kdeplot(y_pred, color='b', label=predicted_label, ax=ax) #predicted values\n",
    "\n",
    "    #showing title\n",
    "    plt.title(title)\n",
    "    #showing legend\n",
    "    plt.legend()\n",
    "    #showing plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kde_actual_vs_predicted(y_test, y_test_pred_custom, \n",
    "                             'Actual vs Predicted values', 'Actual Values', 'Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residual_vs_predicted(y, y_pred, title, x_label, y_label):\n",
    "    #figure size\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    #residual plot\n",
    "    sns.residplot(x=y, y=y_pred)\n",
    "\n",
    "    #labeling\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residual_vs_predicted(y_test, y_test_pred_custom, \n",
    "                         'Residuals versus predicted values plot',\n",
    "                         'Predicted values for Diabetes', 'Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion from plots:\n",
    "\n",
    "1. Actual V/s Predicted Plot: Plotting actual data against the fitted line shows if there is NO clear tendency for points to be distributed around the line.\n",
    "2. KDE of actual and predicted - Probability density of predicted values ​​does NOT approximate real values\n",
    "3. Residual versus predicted: Residuals are indeed randomly distributed uniformly around the fitted line, but the error is too high. This confirms that linear regression is not a good model for this ML problem, and another one must be sought. A regularized version of Linear Regression will also not work because as we have seen, the R2 with training data is also very bad\n",
    "\n",
    "We will next try out sklearn based\n",
    "1. Linear Regression, followed by \n",
    "2. Ridge and Lasso Regression to demo \n",
    "    * Regularization by using GridSearchCV for tuning lambda hyperparameter and also \n",
    "    * To prove the point above wrt regularised Regression that it will not work\n",
    "3. Finally a Polynomial Regression is also tried for completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use sklearn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Convert the iris dataset to a pandas dataframe\n",
    "df = pd.DataFrame(data.data, columns=[\"age\",\"sex\",\"bmi\",\"bp\", \"tc\", \"ldl\", \"hdl\",\"tch\", \"ltg\", \"glu\"])\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "df['target'] = data.target\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is very low. This shows that very less of variance is explained by linear model and there is non linear component to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_sklearn = model.predict(X_train)\n",
    "y_test_pred_sklearn = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Linear Regression Metrics\n",
    "print(f'Mean absolute error is:{mean_absolute_error(y_test, y_test_pred_custom): .2f}')\n",
    "print(f'Root mean squared error is:{np.sqrt(mean_squared_error(y_test, y_test_pred_custom)): .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_train, y_train_pred_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_test_pred_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Lasso (L1) regularized Linear Regression\n",
    "\n",
    "$$\n",
    "\\arg \\min_w \\nabla_w \\mathcal{J} + \\lambda_1 \\nabla_w \\|w\\|_1 \\\\\n",
    "\\nabla_w \\mathcal{J} = \\frac{2}{m} X^T (Xw - y) \\\\\n",
    "\\nabla_w \\|w\\|_1 = \\mathbf{1} \\\\\n",
    "\\textbf{w} = (\\textbf{w} -\\eta \\lambda) - \\eta \\nabla_w \\mathcal{J} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the lasso model\n",
    "model = Lasso()\n",
    "\n",
    "#define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# efine grid\n",
    "grid = dict()\n",
    "grid['alpha'] = np.arange(0, 1, 0.01)\n",
    "\n",
    "#define search - here using a mean absolute error instead of mean squared error\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "#performing the search on the train dataset\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "#printing\n",
    "print(f'MAE:{results.best_score_: .2f}')\n",
    "print(f'Best Alpha:{results.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Lasso()\n",
    "\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "\n",
    "#define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "#printing\n",
    "print(f'MAE:{results.best_score_: .2f}')\n",
    "print(f'Best Alpha:{results.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lasso with best alpha\n",
    "model_best = Lasso(alpha=0.01).fit(X_train, y_train)\n",
    "\n",
    "#predictions\n",
    "y_train_pred = model_best.predict(X_train)\n",
    "y_test_pred = model_best.predict(X_test)\n",
    "\n",
    "print(r2_score(y_train, y_train_pred))\n",
    "print(r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above metrics and alpha shows that regularization did not result in better test predictions. Further confirming that Linear model is not the way to go here\n",
    "\n",
    "Exercise:\n",
    "1. Try applying RidgeRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Polynomial Regression\n",
    "\n",
    "We will use polynomial regression in a pipeline and perform grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Convert the iris dataset to a pandas dataframe\n",
    "df = pd.DataFrame(data.data, columns=[\"age\",\"sex\",\"bmi\",\"bp\", \"tc\", \"ldl\", \"hdl\",\"tch\", \"ltg\", \"glu\"])\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "df['target'] = data.target\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def PolynomialRegression(degree=2):\n",
    "    return Pipeline([('poly', PolynomialFeatures(degree)),\n",
    "                     ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PolynomialRegression(5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.score(X_train, y_train)\n",
    "print(f'R2 score (train): {train_score:.5f}')\n",
    "\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f'R2 score (test): {test_score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation from above result: Excellent R2 on train and really bad score on test indicates overfitting\n",
    "\n",
    "\n",
    "##### 7.1 Visualizing polynomial fit efficacy\n",
    "\n",
    "When the data set is not two-dimensional, it is not possible to plot the polynomials in order to find the best fit to the data. A plot that can help you find the optimal polynomial degree in this case is a validation curve. A validation curve is a graph that shows the training and validation scores for various values of a given parameter. It is similar to a grid search with a single parameter, but it also allows you to plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "degree = np.arange(1, 6)\n",
    "train_scores, val_scores = validation_curve(\n",
    "                                PolynomialRegression(), \n",
    "                                X_train, y_train, \n",
    "                                param_name='poly__degree', \n",
    "                                param_range=degree, \n",
    "                                cv=10\n",
    "                           )\n",
    "plt.plot(degree, np.mean(train_scores, axis=1), 'b', label='training set')\n",
    "plt.plot(degree, np.mean(val_scores, axis=1), 'r', label='validation set')\n",
    "plt.legend()\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('$R^2$ score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'poly__degree': np.arange(1, 6),\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(PolynomialRegression(), param_grid, cv=10, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that polynomial of degree 1 and 2 provide the same score, we stick to the simplest one - i.e. Linear Regression.\n",
    "\n",
    "However it is interesting to see what Polynomial Features sklearn transformer does to the data X.\n",
    "See next cell for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "poly.fit_transform(X_train) # Puts 1 in first cell, x, x^2 and x^3 feature crosses in subsequent cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.1 Alternative approaches to polynomial regression \n",
    "\n",
    "Polynomial regression is one example of regression models that use basis functions to model the relationship between two variables. In this type of models, the target variable y is modeled as a linear combination of a set of d basis functions of the input x:\n",
    "\n",
    "$$\n",
    "h(x) = w_0 + w_1 \\varphi_1(x) + w_2 \\varphi_2(x) + ......\n",
    "$$\n",
    "\n",
    "In polynomial regression, the basis functions are just the powers of x. Other popular families of basis functions include radial basis functions (RBF), splines, and wavelets. These families often provide a better fit to the data than polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Applying normal equation directly for small datasets\n",
    "$$\n",
    "w = (X^TX)^{-1}X^Ty \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Convert the iris dataset to a pandas dataframe\n",
    "df = pd.DataFrame(data.data, columns=[\"age\",\"sex\",\"bmi\",\"bp\", \"tc\", \"ldl\", \"hdl\",\"tch\", \"ltg\", \"glu\"])\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "df['target'] = data.target\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_withones = np.hstack((np.ones(X.shape[0]).reshape(-1,1), X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_withones, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = (X^TX)^-1 X^Ty\n",
    "w = np.dot(\n",
    "        np.dot(\n",
    "            np.linalg.inv(np.dot(X_train.T, X_train)), \n",
    "            X_train.T), \n",
    "        y_train)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.dot(X_test, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_true=y_test, y_pred=y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. OLS from Statsmodel package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/debajyotipodder/co2-emission-by-vehicles\n",
    "df = pd.read_csv(\"data/co2_emissions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease of use in our regression, we drop character columns\n",
    "# In reality you might want to encode these in some appropriate way\n",
    "\n",
    "df.drop(['Make','Model','Vehicle Class','Transmission','Fuel Type'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "\n",
    "style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "#plt.savefig('pairplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'Engine Size(L)', y = 'CO2 Emissions(g/km)', data = df, s = 100, alpha = 0.3, edgecolor = 'white')\n",
    "plt.title('Engine size vs C02 Emissions', fontsize = 16)\n",
    "plt.ylabel('CO2 Emissions', fontsize = 12)\n",
    "plt.xlabel('Engine Size', fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'Fuel Consumption Comb (L/100 km)', y = 'CO2 Emissions(g/km)', data = df, s = 100, alpha = 0.3, edgecolor = 'white')\n",
    "plt.title('Fuel Consumption Comb (L/100 km) vs C02 Emissions', fontsize = 16)\n",
    "plt.ylabel('CO2 Emissions', fontsize = 12)\n",
    "plt.xlabel('Fuel Consumption Comb (L/100 km)', fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot = True, cmap = 'magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: \n",
    "1. Fuel consumption is highly negatively correlated with every other feature.\n",
    "2. A lot of other columns are highly positively correlated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.1 Simple Linear Regression \n",
    "\n",
    "With one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var = df[['Engine Size(L)']] # independent variable\n",
    "y_var = df['CO2 Emissions(g/km)'] # dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. !pip install statsmodels  - run this command in conda shell\n",
    "2. !pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "slr_model = sm.OLS(y_var, X_var) # Ordinary Least Squares \n",
    "slr_reg = slr_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored as cl\n",
    "\n",
    "print(cl(slr_reg.summary(),attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Linear Regression with OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_var = df[['Engine Size(L)','Fuel Consumption Comb (L/100 km)',\n",
    "             'Fuel Consumption Hwy (L/100 km)','Fuel Consumption City (L/100 km)']]\n",
    "y_var = df['CO2 Emissions(g/km)'] # dependent variable\n",
    "\n",
    "\n",
    "sm_X1_var = sm.add_constant(X1_var)\n",
    "mlr_model = sm.OLS(y_var, sm_X1_var)\n",
    "mlr_reg = mlr_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl(mlr_reg.summary(), attrs = ['bold']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "1. Not only Adjusted R-squared, but also R2 itself dropped when adding second feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Perform Linear Regression using the advertising dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Demoing usage of Lasso (L1) regression elimination of features\n",
    "\n",
    "1. As alpha (lambda) increases, the number of features eliminated increases\n",
    "\n",
    "Using the Energy efficiency data from https://archive.ics.uci.edu/dataset/242/energy+efficiency\n",
    "\n",
    "**Important** !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data/ENB2012_data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. X1 Relative Compactness\n",
    "2. X2 Surface Area\n",
    "3. X3 Wall Area\n",
    "4. X4 Roof Area\n",
    "5. X5 Overall Height\n",
    "6. X6 Orientation\n",
    "7. X7 Glazing Area\n",
    "8. X8 Glazing Area Distribution\n",
    "9. y1 Heating Load\n",
    "10. y2 Cooling Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df.pop(\"Y1\")\n",
    "y2 = df.pop(\"Y2\")\n",
    "X = df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha = 0.1)\n",
    "lasso_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the coefficients\n",
    "df_coef_lasso = pd.DataFrame({\"var\": X_train.columns.values, \n",
    "                              \"coef\":lasso_model.coef_})\n",
    "df_coef_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = lasso_model.predict(X_test)\n",
    "lasso_model.score(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary modules\n",
    "from itertools import cycle\n",
    "from sklearn.linear_model import lasso_path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#run the lasso path\n",
    "alphas_lasso, coefs_lasso, _ = lasso_path(X_train, y_train.values.reshape(-1),\n",
    "                                          alphas = [.0001, .001, .01,.1, .5, 1, 10, 100, 1000, 10000])\n",
    "#plot the coefficients over the path\n",
    "log_alphas_lasso = np.log10(alphas_lasso)\n",
    "for index, coef_l in enumerate(coefs_lasso):\n",
    "    l1 = plt.plot(log_alphas_lasso, coef_l,\n",
    "                 label = X_train.columns.values[index])\n",
    "#add labels\n",
    "plt.xlabel('Log(alpha)')\n",
    "plt.ylabel('coefficients')\n",
    "plt.title('Lasso Path')\n",
    "plt.axis('tight')\n",
    "plt.legend(bbox_to_anchor = (0.7, 0.3, 0.5, 0.5))\n",
    "#sho the model\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The above plot shows how each feature becomes irrelevant as alpha increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Heteroskedasticity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/moscow_apartment_listings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping categorical variables before OLS. To use categorical variables in OLS, refer to this - https://www.datarobot.com/blog/multiple-regression-using-statsmodels/. Alternatively you will also learn this in AAPS subject in second semester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(char_cols)\n",
    "df.drop(char_cols, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df.pop(\"price\")\n",
    "#X = df #.to_numpy()\n",
    "#X = sm.add_constant(X)\n",
    "#model = sm.OLS(y,X)\n",
    "#model = model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf \n",
    "# formula: response ~ predictor + predictor \n",
    "est = smf.ols(formula='price ~ repair + year_built_empty + house_age + dist_to_subway', data=df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detecting Heteroscedasticity**\n",
    "Among several dozen methods to detect Heteroskedasticity, here we use Het-White Test. The methodology is as follows:\n",
    "1. First, we make two hypotheses: Null (H0) and Alternate (H1).\n",
    "    * H0: The dataset has homoskedasticity.\n",
    "    * H1: The dataset does not have homoskedasticity but Heteroscedasticity.\n",
    "2. The test returns values for ‘Lagrange Multiplier statistic’, ‘LM test’s p-value’, ‘F-statistic’, and ‘F-test’s p-value’. \n",
    "3. If the P-value output is less than 0.05. Then we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.compat import lzip\n",
    "from patsy import dmatrices\n",
    "\n",
    "expr = 'price ~ repair + year_built_empty + house_age + dist_to_subway'\n",
    "y, X = dmatrices(expr, df, return_type='dataframe')\n",
    "\n",
    "keys = ['Lagrange Multiplier statistic:', 'LM test\\'s p-value:', 'F-statistic:', 'F-test\\'s p-value:']\n",
    "results = het_white(model.resid, X)\n",
    "lzip(keys, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm              ## Performing statistical methods\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    ## For checking Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calculating VIF, we need to remove columns with NA or impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing percentage\n",
    "(df.isna().sum(axis=0)/df.shape[0]).plot(kind = 'bar',ylim = (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 20% missing values\n",
    "missing_percent = df.isna().sum(axis=0)/df.shape[0]\n",
    "drop_cols = missing_percent[missing_percent > 0.2].index\n",
    "df.drop(columns=drop_cols,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Date' , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percent = df.isna().sum(axis=0)/df.shape[0]\n",
    "missing_percent.plot(kind='bar',ylim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'].replace({'No':0, 'Yes': 1}, inplace = True)\n",
    "df['RainToday'].replace({'No':0, 'Yes': 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(df.select_dtypes(exclude='object'))\n",
    "categorical_cols = ['Location']\n",
    "ordinal_cols = list(set(df.columns) - set(numeric_cols) - set(categorical_cols))\n",
    "numeric_cols.remove('RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(df.select_dtypes(exclude='object'))\n",
    "categorical_cols = ['Location']\n",
    "ordinal_cols = list(set(df.columns) - set(numeric_cols) - set(categorical_cols))\n",
    "numeric_cols.remove('RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for feature in categorical_cols+ordinal_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[feature] = label_encoder.fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "print(\"Relation with RainTomorrow at p = 0.05 \")\n",
    "for feature in categorical_cols+ordinal_cols:\n",
    "    data = pd.crosstab(df[feature],df['RainTomorrow'])\n",
    "    stat, p , dof , expected = chi2_contingency(data)\n",
    "    if p <= 0.05:\n",
    "        print('{0} : Related ' .format(feature))\n",
    "    else:\n",
    "        print('{0} : Not Related' .format(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize' : (16,16)})\n",
    "sns.heatmap(df[numeric_cols].corr(), annot = True , \n",
    "            cmap=sns.color_palette(\"crest\", as_cmap=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate VIF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "ind_features = df[numeric_cols]\n",
    "vif_data['feature'] = ind_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data['VIF'] = [variance_inflation_factor(ind_features.values, i)\n",
    "                       for i in range(len(ind_features.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data.sort_values(by='VIF',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. A lots of very high VIFs...\n",
    "2. But not all of these features need to be deleted\n",
    "3. We can cleverly creagte some new features out of these as shown below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copy of current dataframe before changes\n",
    "df_before_vif_fix = df.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pressure_Interval'] = abs(df['Pressure9am'] - df['Pressure3pm'])\n",
    "df['Humidity_Interval'] = abs(df['Humidity9am'] - df['Humidity3pm'])\n",
    "df['TempInterval'] = abs(df['Temp9am'] - df['Temp3pm'])\n",
    "df['WindSpeedInterval'] = abs(df['WindSpeed9am'] - df['WindSpeed3pm'])\n",
    "df['Temperature_Interval'] = abs(df['MaxTemp'] - df['MinTemp'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the columns that contributed to the difference calc above\n",
    "df.drop(columns=['Pressure9am','Pressure3pm','MaxTemp','MinTemp','WindDir9am','WindDir3pm',\n",
    "                 'Humidity9am','Humidity3pm','Temp9am','Temp3pm','WindSpeed9am','WindSpeed3pm'],\n",
    "                 axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_features = df.drop('RainTomorrow',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = list(df.select_dtypes(exclude='object'))\n",
    "vif_data = pd.DataFrame()\n",
    "ind_features = df[numeric_cols]\n",
    "vif_data['feature'] = ind_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data[\"VIF\"] = [variance_inflation_factor(ind_features.values, i)\n",
    "                          for i in range(len(ind_features.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data.sort_values(by='VIF',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop features with VIF > 0 and apply linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(vif_data[vif_data['VIF']>5]['feature']),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
