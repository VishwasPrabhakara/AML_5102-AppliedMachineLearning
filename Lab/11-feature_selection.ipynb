{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Demo: Random Forest Feature Importance for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mnist.data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine label into dataframe\n",
    "df['label'] = mnist.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at features and labels separately\n",
    "X = df.iloc[:,0:-1:]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = X.iloc[0].values.reshape(28,28)\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X.iloc[0].values.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf.feature_importances_.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(rf.feature_importances_ > 0.004)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Remove constant/quasi-constant features\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^n (x^{(i)}-\\bar{x})^2\n",
    "$$\n",
    "\n",
    "| F1 | F2 | F3 | F4 |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 0 | 1 | 2 |\n",
    "| 2 | 8 | 1 | 2 |\n",
    "| 4 | 5 | 1 | 2 |\n",
    "| 6 | 6 | 1 | 0 |\n",
    "| 9 | 4 | 1 | 2 |\n",
    "\n",
    "\n",
    "1. Features with zero or low variance do not explain the target variable in any way (i.e. no predictive power).\n",
    "2. Such features can be removed by using VarianceThreshold transformer\n",
    "3. It takes a threshold cut-off value. All values below that threshold value will be dropped\n",
    "4. Default threshold value = 0. It drops only constant\n",
    "5. A quasi-constant feature, using a threshold of 0.1 means 90% of the values are similar\n",
    "6. Although not mandatory, normalizing (not standardizing) the features before applying VarianceThreshold is a good idea for exploratory purposes of fairer comparison of variance across features and set a cutoff. Otherwise variance is a running value\n",
    "7. Can be applied for Categorical variables after Label/Ordinal Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**:\n",
    "Used below is a public dataset from 2012 U.S. Army Anthropometric Survey: http://mreed.umtri.umich.edu/mreed/downloads/anthro/ANSUR2Distribution.zip. The zip contains CSV for male and female. Only make dataset is used for testing VarianceThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demo\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = [['blue'], ['green'], ['blue'], ['blue'], \n",
    "     ['green'], ['red'], ['blue'], ['green']]\n",
    "y = [0, 0, 1, 0, 0, 1, 0, 0]\n",
    "\n",
    "enc = OneHotEncoder(drop='first')\n",
    "enc.fit(X)\n",
    "X_ohe = enc.transform(X)\n",
    "X_ohe.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "\n",
    "sel.fit(X_ohe)\n",
    "sel.transform(X_ohe).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On real dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ANSUR II MALE Public.csv\", encoding='latin')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"subjectid\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # 107 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ANSUR II MALE Public.csv\", encoding='latin')\n",
    "df.drop(columns=[\"subjectid\"], inplace=True)\n",
    "\n",
    "df = df.select_dtypes(include='number')\n",
    "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Run with all features\n",
    "\n",
    "Note the accuracy and time taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train, y_train)\n",
    "print(f\"Training Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Identify quasi-constant features with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = X_train.mean()\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / x_mean\n",
    "X_test_normalized = X_test/x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_constant_features = [feat for feat in X_train.columns if X_train_normalized[feat].var() <= 0.03]\n",
    "print(quasi_constant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3. Identify quasi-constant features with VarianceThreshold\n",
    "\n",
    "1. StandardScaler is not used because it sets variance = 1\n",
    "2. Normalizer is not used because the output of the transformer will no longer be a dataframe. We will do it from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#normalizer = Normalizer()\n",
    "#X_train_normalized = normalizer.fit_transform(X_train)\n",
    "#X_test_normalized = normalizer.transform(X_test)\n",
    "\n",
    "# Normalizer is not used because the output is no longer a dataframe.\n",
    "# We will do it frm scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = X_train.mean()\n",
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train / x_mean\n",
    "X_test_normalized = X_test/x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: Applying a threshold of 0.003 removes approximately 50% of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(X_train_normalized.var() > 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(X_train_normalized.var() > 0.003)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "vt = VarianceThreshold(threshold=0.003)\n",
    "vt.fit_transform(X_train_normalized)\n",
    "\n",
    "mask = vt.get_support()\n",
    "mask # mask tells which column to retain or remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_normalized.loc[:, mask]\n",
    "X_test_final = X_test_normalized.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt.get_feature_names_out() #show the retained features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final.shape # Ensure that the number of columns is half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42)\n",
    "_ = model.fit(X_train_final, y_train)\n",
    "print(f\"Training Score: {model.score(X_train_final, y_train)}\")\n",
    "print(f\"Test Score: {model.score(X_test_final, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: \n",
    "1. Time taken for model training is reduced by more than half.\n",
    "2. Model accuracy is not at all affected on both train and test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Identify quasi-constant features with Feature Engine\n",
    "\n",
    "1. !pip install feature-engine\n",
    "2. Feature-engine is an open source Python library with the most exhaustive battery of transformers to engineer features for use in machine learning models. Feature-engine simplifies and streamlines the implementation of and end-to-end feature engineering pipeline, by allowing the selection of feature subsets within its transformers, and returning dataframes for easy data exploration. Feature-engine’s transformers preserve Scikit-learn functionality with the methods fit() and transform() to learn parameters from and then transform data\n",
    "3. https://feature-engine.trainindata.com/en/latest/\n",
    "4. https://feature-engine.trainindata.com/en/latest/api_doc/index.html\n",
    "5. https://feature-engine.trainindata.com/en/latest/user_guide/selection/DropConstantFeatures.html\n",
    "6. DropConstantFeatures takes a tolerance level. E.g. tol=.7 to remove features that show the same value in more than 70% of the observations\n",
    "7. Here is a good executive summary of available product features: https://trainindata.medium.com/feature-engine-a-new-open-source-python-package-for-feature-engineering-29a0ab88ea7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from feature_engine.datasets import load_titanic\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "X, y = load_titanic(return_X_y_frame=True, handle_missing=True,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape # 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['embarked'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** More than 70% of values in the embarked feature are same viz S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DropConstantFeatures(tol=0.7)\n",
    "transformer.fit(X_train)\n",
    "transformer.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vars = transformer.transform(X_train)\n",
    "X_test_vars = transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vars.shape # 4 features dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.get_support() #this is similar to sklearn VarianceThreshold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Highly correlated features\n",
    "\n",
    "While high correlation between feature and target is good, high correlation between features is not good\n",
    "\n",
    "##### 3.1 Visualize heatmap\n",
    "\n",
    "**Warning**\n",
    "1. Correlation is a linear measure. \n",
    "2. There can be non linear relation. That will not be measured by pearson's correlation \n",
    "3. Use mutual information to measure that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df_housing[\"target\"] = housing.target\n",
    "df_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the size of the heatmap.\n",
    "plt.figure(figsize=(16, 6))\n",
    "# Store heatmap object in a variable to easily access it when \n",
    "# you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and \n",
    "# set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(df_housing.corr(), vmin=-1, vmax=1, annot=True)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: AveRooms and AveBedrooms are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_housing[\"AveRooms\"], df_housing[\"AveBedrms\"], alpha=0.3, color=\"purple\")\n",
    "plt.xlabel(\"var_8\")\n",
    "plt.ylabel(\"var_6\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diverging color palette that has markedly different colors at the two ends of the value-range with a pale, almost colorless midpoint, works much better with correlation heatmaps than the default colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "heatmap = sns.heatmap(df_housing.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);\n",
    "\n",
    "#plt.savefig('heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing target column with triu-1 lets us focus only on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(df_housing.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df_housing.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Spearman correlation\n",
    "\n",
    "In this case Spearman correlation does not deviate much from pearson for Latitude and Longitude. However Spearmzn correlation between AveRooms and AvgBedrooms very less. Correpsonding pearson correlation was high. This indicates either one of those two columns contain outliers or some other reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# define the mask to set the values in the upper triangle to True\n",
    "mask = np.triu(np.ones_like(df_housing.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df_housing.corr(method=\"spearman\"), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Using Feature Engine to drop correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of features: {df_housing.iloc[:,:-1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "\n",
    "sel = DropCorrelatedFeatures(method=\"pearson\", threshold=0.8)\n",
    "sel.fit(df_housing.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.correlated_feature_sets_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_corr = sel.transform(df_housing.iloc[:,:-1]) # 2 columns are dropped \n",
    "X_no_corr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Remove correlated features and retain the best correlated feature with target\n",
    "\n",
    "1. Removing correlated features in previous section removed all but one correlated feature.\n",
    "2. But there is no guarantee that the retained feature is the one that has best correlation with target variable\n",
    "3. In a given dataset, we can find groups of features that are correlated among themselves or to a given feature. From every one of these groups, we can retain the feature that brings most value to the\n",
    "predictive model and remove the rest\n",
    "4. FeatureEngine provides a class called SmartCorrelatedSelection for this purpose. \n",
    "5. SmartCorrelatedSelection identifies features with a correlation coefficient higher configured value, then retain the feature with the highest importance from each group of correlated variables.\n",
    "6. In this sense it is a wrapper method, but the goal it achieves is similar to Filter method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_housing.iloc[:,:-1]\n",
    "y = df_housing.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "sel = SmartCorrelatedSelection(method=\"pearson\", threshold=0.8, \n",
    "                               selection_method=\"model_performance\",\n",
    "                               estimator=RandomForestRegressor(n_estimators=5, random_state=10),\n",
    "                               scoring=\"r2\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorrel = sel.transform(X_train)\n",
    "X_test_uncorrel = sel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_uncorrel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Filter methods\n",
    "\n",
    "1. All filter methods are supervised.\n",
    "2. Implemented froms scratch and with SelectKBest\n",
    "\n",
    "##### 4.1 Data preprocessing of Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic=sns.load_dataset('titanic')\n",
    "\n",
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = titanic[0]\n",
    "df_titanic['survived'] = titanic[1] \n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Unique values for feature cabin {df_titanic['cabin'].nunique()}\")\n",
    "print(f\"Unique values for feature body {df_titanic['body'].nunique()}\")\n",
    "print(f\"Unique values for feature boat {df_titanic['boat'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['survived'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.drop(columns=[\"name\", \"ticket\", \"cabin\", \"body\", \"home.dest\", \"boat\"], inplace=True)\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_titanic[\"embarked\"].isna()\n",
    "np.where(df_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.drop(np.where(df_titanic[\"embarked\"].isna())[0], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"fare\"].isna())[0], inplace=True)\n",
    "df_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_titanic.iloc[:,:-1:]\n",
    "y = df_titanic.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl_encoder = LabelEncoder()\n",
    "sex_train_encoded = lbl_encoder.fit_transform(X_train[\"sex\"])\n",
    "sex_test_encoded = lbl_encoder.transform(X_test[\"sex\"])\n",
    "\n",
    "lbl_encoder2 = LabelEncoder()\n",
    "embark_train_encoded = lbl_encoder.fit_transform(X_train[\"embarked\"])\n",
    "embark_test_encoded = lbl_encoder.transform(X_test[\"embarked\"])\n",
    "\n",
    "tgt_encoder = LabelEncoder()\n",
    "y_train_encoded = tgt_encoder.fit_transform(y_train)\n",
    "y_test_encoded = tgt_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.hstack( \n",
    "    (X_train.iloc[:,0:1].to_numpy(), sex_train_encoded.reshape(-1,1), \n",
    "     X_train.iloc[:,2:6].to_numpy(), embark_train_encoded.reshape(-1,1)))\n",
    "X_test_new = np.hstack(\n",
    "    (X_test.iloc[:,0:1].to_numpy(), sex_test_encoded.reshape(-1,1), \n",
    "     X_test.iloc[:,2:6].to_numpy(), embark_test_encoded.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=7, weights='uniform', metric='nan_euclidean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_new)\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Finding feature importance with mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.contingency import crosstab\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1 direct\n",
    "mi = mutual_info_score(y_train, X_train['sex'])\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 get crosstab first and then mi\n",
    "c = crosstab(y_train, X_train['sex'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_score(labels_true=None, labels_pred=None, contingency = c[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** There is mutual information between sex and survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Find mutual information in the most direct manner between all features and categorical target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "mi_score = mutual_info_classif(X_train_imputed, y_train, n_neighbors=10, random_state=22)\n",
    "sorted_idx = np.argsort(mi_score)\n",
    "mi_scoredf = pd.DataFrame(\n",
    "    mi_score[sorted_idx[::-1]], \n",
    "    index=X_train.columns[sorted_idx[::-1]], \n",
    "    columns=['mi_score'])\n",
    "plt.barh(\n",
    "    X_train.columns[sorted_idx], \n",
    "    mi_score[sorted_idx])\n",
    "plt.xlabel(\"Mutual Information Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Mutual Information between numerical/categorical feature and a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "#fare and age\n",
    "mutual_info_regression(X_train_imputed[:,5].reshape(-1,1), \n",
    "                       X_train_imputed[:,2], discrete_features=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.5 Find feature importance with chi square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.crosstab(y_train, X_train['sex'])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "chi2_contingency(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_ls = []\n",
    "for feature in X_train.columns: # create contingency table\n",
    "    c = pd.crosstab(y_train, X_train[feature])\n",
    "    # chi-square test\n",
    "    p_value = chi2_contingency(c)[1]\n",
    "    chi_ls.append(p_value)\n",
    "\n",
    "pd.Series(chi_ls, index=X_train.columns).sort_values(ascending=True).plot.bar(rot=45)\n",
    "plt.ylabel(\"p value\")\n",
    "plt.title(\"Feature importance based on chi-square test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.Series(chi_ls, index=X_train.columns).sort_values(ascending=True)[0:3].index\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6 Feature Selection with SelectKBest and scoring = chisquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(score_func=chi2, k=4)\n",
    "fit = kbest.fit(X_train_imputed, y_train)\n",
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.columns[[0,1,5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.6 Feature Selection with SelectKBest and scoring = mutual_info_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest = SelectKBest(score_func=mutual_info_classif, k=4)\n",
    "fit = kbest.fit(X_train_imputed, y_train)\n",
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest.get_feature_names_out() #notice the difference between this and chisquared based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4 Apply chisquared to wine dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "X,y=load_wine(return_X_y=True)\n",
    "\n",
    "# k = 4 tells four top features to be selected\n",
    "# Score function Chi2 tells the feature to be selected using Chi Square\n",
    "wine_kbest = SelectKBest(score_func=chi2, k=4)\n",
    "_ = wine_kbest.fit(X, y)\n",
    "\n",
    "wine_kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_kbest.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Selection with Lasso Regression\n",
    "\n",
    "1. For Lasso with Linear Regression, see linear_regression_reference.ipynb\n",
    "2. Below is code for logistic regression with L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/'\n",
    "                      'ml/machine-learning-databases/wine/wine.data',\n",
    "                      header=None)\n",
    "\n",
    "# if the Wine dataset is temporarily unavailable from the\n",
    "# UCI machine learning repository, un-comment the following line\n",
    "# of code to load the dataset from a local path:\n",
    "\n",
    "# df_wine = pd.read_csv('wine.data', header=None)\n",
    "\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                   'Proline']\n",
    "\n",
    "print('Class labels', np.unique(df_wine['Class label']))\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=1.0, solver='liblinear', multi_class='ovr')\n",
    "# Note that C=1.0 is the default. You can increase\n",
    "# or decrease it to make the regulariztion effect\n",
    "# stronger or weaker, respectively.\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', lr.score(X_train_std, y_train))\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_[lr.coef_!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "    \n",
    "colors = ['blue', 'green', 'red', 'cyan', \n",
    "          'magenta', 'yellow', 'black', \n",
    "          'pink', 'lightgreen', 'lightblue', \n",
    "          'gray', 'indigo', 'orange']\n",
    "\n",
    "weights, params = [], []\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = LogisticRegression(penalty='l1', C=10.**c, solver='liblinear', \n",
    "                            multi_class='ovr', random_state=0)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],\n",
    "             label=df_wine.columns[column + 1],\n",
    "             color=color)\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('Weight coefficient')\n",
    "plt.xlabel('C (inverse regularization strength)')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center', \n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.savefig('lasso-path.pdf', dpi=300, \n",
    "            bbox_inches='tight', pad_inches=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Selection with Feature Importance in Decision Tree\n",
    "\n",
    "1. DIY\n",
    "2. Using sklearn\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_samples=5, n_classes=2,\n",
    "                               n_features=2, n_informative=2, n_redundant=0,\n",
    "                               random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Calculate feature importance using the formula**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate feature importance using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. How Feature Importance is calculated in Random Forest\n",
    "\n",
    "Run the relevant section from bagging_ensemble_randomforest.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Problems with Tree based default feature importance\n",
    "\n",
    "1. Inflated feature importance for numerical feature\n",
    "2. Inflated feature importance for categorical feature with high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "df_titanic = titanic[0]\n",
    "df_titanic['survived'] = titanic[1] \n",
    "df_titanic.drop(columns=[\"name\", \"ticket\", \"cabin\", \"body\", \"home.dest\", \"boat\"], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"embarked\"].isna())[0], inplace=True)\n",
    "df_titanic.drop(np.where(df_titanic[\"fare\"].isna())[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_titanic.iloc[:,:-1:]\n",
    "y = df_titanic.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "X[\"random_cat\"] = rng.randint(3, size=X.shape[0])\n",
    "X[\"random_num\"] = rng.randn(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "lbl_encoder = LabelEncoder()\n",
    "sex_train_encoded = lbl_encoder.fit_transform(X_train[\"sex\"])\n",
    "sex_test_encoded = lbl_encoder.transform(X_test[\"sex\"])\n",
    "\n",
    "lbl_encoder2 = LabelEncoder()\n",
    "embark_train_encoded = lbl_encoder.fit_transform(X_train[\"embarked\"])\n",
    "embark_test_encoded = lbl_encoder.transform(X_test[\"embarked\"])\n",
    "\n",
    "tgt_encoder = LabelEncoder()\n",
    "y_train_encoded = tgt_encoder.fit_transform(y_train)\n",
    "y_test_encoded = tgt_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.hstack( \n",
    "    (X_train.iloc[:,0:1].to_numpy(), sex_train_encoded.reshape(-1,1), \n",
    "     X_train.iloc[:,2:6].to_numpy(), embark_train_encoded.reshape(-1,1)))\n",
    "X_test_new = np.hstack(\n",
    "    (X_test.iloc[:,0:1].to_numpy(), sex_test_encoded.reshape(-1,1), \n",
    "     X_test.iloc[:,2:6].to_numpy(), embark_test_encoded.reshape(-1,1)))\n",
    "\t \n",
    "\t \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=7, weights='uniform', metric='nan_euclidean')\n",
    "X_train_imputed = imputer.fit_transform(X_train_new)\n",
    "X_test_imputed = imputer.fit_transform(X_test_new)\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = np.hstack( (X_train_imputed, X_train.loc[:, [\"random_cat\", \"random_num\"]].to_numpy()))\n",
    "X_test_imputed = np.hstack( (X_test_imputed, X_test.loc[:, [\"random_cat\", \"random_num\"]].to_numpy()))\n",
    "\n",
    "X_train_imputed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "         n_estimators=100,\n",
    "         n_jobs=-1,\n",
    "         min_samples_leaf = 1,\n",
    "         oob_score=True,\n",
    "         random_state = 42)\n",
    "rf.fit(X_train_imputed, y_train)\n",
    "\n",
    "print(f\"RF train accuracy: {rf.score(X_train_imputed, y_train):.3f}\")\n",
    "print(f\"RF test accuracy: {rf.score(X_test_imputed, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "feat_importances = pd.Series(rf.feature_importances_, index = X_train.columns).sort_values(ascending = True)\n",
    "feat_importances.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Permutation based feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#calculate permutation importance for test data \n",
    "result_test = permutation_importance(\n",
    "    rf, X_test_imputed, y_test, n_repeats=20, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx_test = result_test.importances_mean.argsort()\n",
    "importances_test = pd.DataFrame(\n",
    "    result_test.importances[sorted_importances_idx_test].T,\n",
    "    columns=X.columns[sorted_importances_idx_test],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate permutation importance for training data \n",
    "result_train = permutation_importance(\n",
    "    rf, X_train_imputed, y_train, n_repeats=20, random_state=42, n_jobs=2\n",
    ")\n",
    "\n",
    "sorted_importances_idx_train = result_train.importances_mean.argsort()\n",
    "importances_train = pd.DataFrame(\n",
    "    result_train.importances[sorted_importances_idx_train].T,\n",
    "    columns=X.columns[sorted_importances_idx_train],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "importances_test.plot.box(vert=False, whis=10, ax = axs[0])\n",
    "axs[0].set_title(\"Permutation Importances (test set)\")\n",
    "axs[0].axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "axs[0].set_xlabel(\"Decrease in accuracy score\")\n",
    "axs[0].figure.tight_layout()\n",
    "\n",
    "importances_train.plot.box(vert=False, whis=10, ax = axs[1])\n",
    "axs[1].set_title(\"Permutation Importances (train set)\")\n",
    "axs[1].axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "axs[1].set_xlabel(\"Decrease in accuracy score\")\n",
    "axs[1].figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9.2 Drop Column variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "def dropcol_importances(rf, X_train, y_train):\n",
    "    rf_ = clone(rf)\n",
    "    rf_.random_state = 42\n",
    "    rf_.fit(X_train, y_train)\n",
    "    \n",
    "    #use out of bag error as performance measurement\n",
    "    baseline = rf_.oob_score_\n",
    "    imp = []\n",
    "    for col in X_train.columns:\n",
    "        X = X_train.drop(col, axis=1)\n",
    "        rf_ = clone(rf)\n",
    "        rf_.random_state = 42\n",
    "        rf_.fit(X, y_train)\n",
    "        o = rf_.oob_score_\n",
    "        imp.append(baseline - o)\n",
    "    imp = np.array(imp)\n",
    "    I = pd.DataFrame(\n",
    "            data={'Feature':X_train.columns,\n",
    "                  'Importance':imp})\n",
    "    I = I.set_index('Feature')\n",
    "    I = I.sort_values('Importance', ascending=True)\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_train = pd.DataFrame(data=X_train_imputed, columns=X_train.columns)\n",
    "imp = dropcol_importances(rf, df_titanic_train, y_train)\n",
    "imp.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', random_state=123)\n",
    "\n",
    "rfe = RFE(estimator=lr, n_features_to_select=5, step=1)\n",
    "rfe.fit(X_train_imputed, y_train)\n",
    "\n",
    "X_train_sub = rfe.transform(X_train_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which features got selected?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. RFE as part of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "pipe = make_pipeline(RFE(estimator=lr, step=1),\n",
    "                     KNeighborsClassifier())\n",
    "\n",
    "\n",
    "parameters = {'rfe__n_features_to_select': range(1, 13), \n",
    "              'kneighborsclassifier__n_neighbors': range(1, 10) }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=parameters, cv=10, n_jobs=-1)\n",
    "grid.fit(X_train_imputed, y_train)\n",
    "\n",
    "print('Best params:', grid.best_params_)\n",
    "print('Best accuracy:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_.score(X_test_imputed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate implementation to compare performance\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_imputed, y_train)\n",
    "knn.score(X_test_imputed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RFE add-on with Yellow bricks**\n",
    "\n",
    "Not working as of now due to dataset issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# from yellowbrick.model_selection import rfecv\n",
    "# from yellowbrick.datasets import load_bikeshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load classification dataset\n",
    "# X, y = load_bikeshare()\n",
    "\n",
    "# cv = StratifiedKFold(5)\n",
    "# visualizer = rfecv(RandomForestClassifier(), X=X, y=y, cv=cv, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
